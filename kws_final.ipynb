{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP50ioAFZLFPrR+MH0v7Tt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamiit3924/Keyword_Spotting/blob/main/kws_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs7asLQHhYF4",
        "outputId": "25597fa5-8cf7-4b96-b3da-4b4cbf6c25e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/New folder/Copy of data.csv\""
      ],
      "metadata": {
        "id": "m2Og7ccZhe_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(path)\n",
        "print(\"Shape:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIM3bnkQiFZN",
        "outputId": "82ba514f-9985-4679-acab-2fcd93125839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (34176, 1275)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Information:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()[:5]}...\")  # Show first 5 column names\n",
        "print(f\"Total rows: {len(df)}\")\n",
        "print(f\"Total columns: {len(df.columns)}\")\n",
        "\n",
        "# Look at the data\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check the last column (assuming it's labels)\n",
        "print(f\"\\nLast column name: {df.columns[-1]}\")\n",
        "print(f\"Unique values in last column: {df.iloc[:, -1].unique()}\")\n",
        "print(f\"Number of unique labels: {len(df.iloc[:, -1].unique())}\")\n",
        "\n",
        "# Count of each label\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df.iloc[:, -1].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNb2SR9UseQw",
        "outputId": "9ccd78ae-1a73-4ce5-8532-b091f7877ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n",
            "Shape: (34176, 1275)\n",
            "Columns: ['-288.14898681640625', '-300.1120910644531', '-313.1480712890625', '-314.75970458984375', '-315.8346252441406']...\n",
            "Total rows: 34176\n",
            "Total columns: 1275\n",
            "\n",
            "First 5 rows:\n",
            "   -288.14898681640625  -300.1120910644531  -313.1480712890625  \\\n",
            "0          -556.491821         -546.531921         -549.918579   \n",
            "1          -628.486267         -622.119751         -622.733765   \n",
            "2          -570.658813         -564.907715         -563.779236   \n",
            "3          -579.377136         -575.636536         -573.867920   \n",
            "4          -595.857666         -580.376892         -582.433777   \n",
            "\n",
            "   -314.75970458984375  -315.8346252441406  -314.03369140625  \\\n",
            "0          -459.302795         -189.527100        -92.891487   \n",
            "1          -622.907471         -619.837158       -619.732117   \n",
            "2          -304.617157         -132.021194        -74.879395   \n",
            "3          -573.770508         -574.695862       -421.262390   \n",
            "4          -584.296204         -584.109131       -583.679382   \n",
            "\n",
            "   -315.5007019042969  -312.1968078613281  -310.1685485839844  \\\n",
            "0          -71.578926          -80.738289          -94.240479   \n",
            "1         -620.732239         -621.867859         -610.511047   \n",
            "2          -76.921280          -94.568428         -115.134766   \n",
            "3         -187.168259          -96.298080          -71.182701   \n",
            "4         -581.617493         -585.494446         -587.197571   \n",
            "\n",
            "   -311.72503662109375  ...  0.0.849  0.0.850  0.0.851  0.0.852  0.0.853  \\\n",
            "0          -146.123215  ...      0.0      0.0      0.0      0.0      0.0   \n",
            "1          -292.308807  ...      0.0      0.0      0.0      0.0      0.0   \n",
            "2          -185.907013  ...      0.0      0.0      0.0      0.0      0.0   \n",
            "3           -69.216988  ...      0.0      0.0      0.0      0.0      0.0   \n",
            "4          -583.602173  ...      0.0      0.0      0.0      0.0      0.0   \n",
            "\n",
            "   0.0.854  0.0.855  0.0.856  0.0.857  backward  \n",
            "0      0.0      0.0      0.0      0.0  backward  \n",
            "1      0.0      0.0      0.0      0.0  backward  \n",
            "2      0.0      0.0      0.0      0.0  backward  \n",
            "3      0.0      0.0      0.0      0.0  backward  \n",
            "4      0.0      0.0      0.0      0.0  backward  \n",
            "\n",
            "[5 rows x 1275 columns]\n",
            "\n",
            "Last column name: backward\n",
            "Unique values in last column: ['backward' 'down' 'forward' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n",
            "Number of unique labels: 10\n",
            "\n",
            "Label distribution:\n",
            "backward\n",
            "yes         4044\n",
            "no          3941\n",
            "down        3917\n",
            "go          3880\n",
            "stop        3872\n",
            "left        3801\n",
            "right       3778\n",
            "up          3723\n",
            "backward    1663\n",
            "forward     1557\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.iloc[:, :-1].values  # All columns except last (1274 features)\n",
        "y = df.iloc[:, -1].values   # Last column (labels)\n",
        "\n",
        "print(\"Data shapes:\")\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Labels (y): {y.shape}\")\n",
        "\n",
        "# Convert text labels to numbers\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "print(f\"\\nLabel mapping:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{i}: {label}\")\n",
        "\n",
        "# Normalize the features (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"\\nFeature scaling done!\")\n",
        "print(f\"Original feature range: {X.min():.2f} to {X.max():.2f}\")\n",
        "print(f\"Scaled feature range: {X_scaled.min():.2f} to {X_scaled.max():.2f}\")\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded  # Keep same proportion of each class\n",
        ")\n",
        "\n",
        "print(f\"\\nData split:\")\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Test samples: {X_test.shape[0]}\")\n",
        "print(f\"Features: {X_train.shape[1]}\")\n",
        "print(f\"Classes: {len(label_encoder.classes_)}\")\n",
        "\n",
        "# Check if data is ready\n",
        "print(f\"\\n✓ Data is ready for training!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3a3M9u7sfPq",
        "outputId": "56f116e6-9e69-4a92-89ca-155091b43ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shapes:\n",
            "Features (X): (34176, 1274)\n",
            "Labels (y): (34176,)\n",
            "\n",
            "Label mapping:\n",
            "0: backward\n",
            "1: down\n",
            "2: forward\n",
            "3: go\n",
            "4: left\n",
            "5: no\n",
            "6: right\n",
            "7: stop\n",
            "8: up\n",
            "9: yes\n",
            "\n",
            "Feature scaling done!\n",
            "Original feature range: -1005.56 to 326.57\n",
            "Scaled feature range: -9.94 to 8.41\n",
            "\n",
            "Data split:\n",
            "Training samples: 27340\n",
            "Test samples: 6836\n",
            "Features: 1274\n",
            "Classes: 10\n",
            "\n",
            "✓ Data is ready for training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a simple neural network (easy for hardware implementation)\n",
        "model = keras.Sequential([\n",
        "    # Input layer: 1274 features\n",
        "    layers.Dense(256, activation='relu', input_shape=(1274,), name='hidden1'),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    # Hidden layer\n",
        "    layers.Dense(128, activation='relu', name='hidden2'),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Output layer: 10 classes\n",
        "    layers.Dense(10, activation='softmax', name='output')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Show model architecture\n",
        "print(\"Model Architecture:\")\n",
        "model.summary()\n",
        "\n",
        "print(f\"\\nModel layers:\")\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if hasattr(layer, 'units'):\n",
        "        print(f\"Layer {i}: {layer.name} - {layer.units} units, activation: {layer.activation.__name__}\")\n",
        "\n",
        "print(f\"\\nModel is ready for training!\")\n",
        "print(f\"Input: 1274 features → Hidden1: 256 → Hidden2: 128 → Output: 10 classes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "1DLJsqokGbQs",
        "outputId": "8c5a1c8f-897b-421c-df2c-c693932f1dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Architecture:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m326,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">326,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m360,586\u001b[0m (1.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">360,586</span> (1.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m360,586\u001b[0m (1.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">360,586</span> (1.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model layers:\n",
            "Layer 0: hidden1 - 256 units, activation: relu\n",
            "Layer 2: hidden2 - 128 units, activation: relu\n",
            "Layer 4: output - 10 units, activation: softmax\n",
            "\n",
            "Model is ready for training!\n",
            "Input: 1274 features → Hidden1: 256 → Hidden2: 128 → Output: 10 classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=20,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGGVeS8oNc2s",
        "outputId": "9b30154d-5450-4075-d937-a6af84426d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.4785 - loss: 1.4944 - val_accuracy: 0.7528 - val_loss: 0.7518\n",
            "Epoch 2/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7308 - loss: 0.8000 - val_accuracy: 0.7892 - val_loss: 0.6094\n",
            "Epoch 3/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7699 - loss: 0.6766 - val_accuracy: 0.8231 - val_loss: 0.5334\n",
            "Epoch 4/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8000 - loss: 0.5884 - val_accuracy: 0.8256 - val_loss: 0.5142\n",
            "Epoch 5/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8089 - loss: 0.5459 - val_accuracy: 0.8370 - val_loss: 0.4878\n",
            "Epoch 6/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8266 - loss: 0.5063 - val_accuracy: 0.8446 - val_loss: 0.4646\n",
            "Epoch 7/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8335 - loss: 0.4811 - val_accuracy: 0.8439 - val_loss: 0.4621\n",
            "Epoch 8/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8465 - loss: 0.4483 - val_accuracy: 0.8490 - val_loss: 0.4404\n",
            "Epoch 9/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8531 - loss: 0.4217 - val_accuracy: 0.8533 - val_loss: 0.4447\n",
            "Epoch 10/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8556 - loss: 0.4099 - val_accuracy: 0.8596 - val_loss: 0.4245\n",
            "Epoch 11/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8577 - loss: 0.4055 - val_accuracy: 0.8565 - val_loss: 0.4230\n",
            "Epoch 12/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8638 - loss: 0.3885 - val_accuracy: 0.8578 - val_loss: 0.4186\n",
            "Epoch 13/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8700 - loss: 0.3683 - val_accuracy: 0.8580 - val_loss: 0.4142\n",
            "Epoch 14/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8775 - loss: 0.3574 - val_accuracy: 0.8609 - val_loss: 0.4100\n",
            "Epoch 15/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8819 - loss: 0.3353 - val_accuracy: 0.8631 - val_loss: 0.4102\n",
            "Epoch 16/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8816 - loss: 0.3452 - val_accuracy: 0.8675 - val_loss: 0.3946\n",
            "Epoch 17/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8858 - loss: 0.3232 - val_accuracy: 0.8670 - val_loss: 0.3959\n",
            "Epoch 18/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8876 - loss: 0.3206 - val_accuracy: 0.8685 - val_loss: 0.3881\n",
            "Epoch 19/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.8885 - loss: 0.3192 - val_accuracy: 0.8679 - val_loss: 0.3905\n",
            "Epoch 20/20\n",
            "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8902 - loss: 0.3091 - val_accuracy: 0.8683 - val_loss: 0.3978\n",
            "Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate your trained model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Model test accuracy (float32): {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5fTqOK4PAoB",
        "outputId": "493f7436-e361-4a3c-c29f-56d480da4f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.4278\n",
            "Model test accuracy (float32): 0.8683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_optimal_scale(data, target_bits=8):\n",
        "    \"\"\"Find optimal scale factor for quantization\"\"\"\n",
        "    if target_bits == 8:\n",
        "        max_val = 127\n",
        "        dtype = np.int8\n",
        "    else:\n",
        "        max_val = 32767\n",
        "        dtype = np.int16\n",
        "\n",
        "    # Use 99.9th percentile instead of max to handle outliers\n",
        "    max_abs = np.percentile(np.abs(data), 99.9)\n",
        "    if max_abs == 0:\n",
        "        return 1.0, dtype\n",
        "\n",
        "    scale = max_val / max_abs\n",
        "    return scale, dtype\n",
        "\n",
        "# Step 1: Calibrate scales using training data\n",
        "print(\"Calibrating quantization scales...\")\n",
        "\n",
        "# Find optimal input scale using training data\n",
        "input_scale, _ = find_optimal_scale(X_train)\n",
        "print(f\"Input scale: {input_scale:.2f}\")\n",
        "\n",
        "# Find optimal scales for each layer\n",
        "layer_scales = {}\n",
        "for i in [0, 2, 4]:\n",
        "    weights, biases = model.layers[i].get_weights()\n",
        "\n",
        "    weight_scale, _ = find_optimal_scale(weights)\n",
        "    bias_scale, _ = find_optimal_scale(biases)\n",
        "\n",
        "    layer_scales[i] = {\n",
        "        'weight_scale': weight_scale,\n",
        "        'bias_scale': bias_scale\n",
        "    }\n",
        "    print(f\"Layer {i}: weight_scale={weight_scale:.2f}, bias_scale={bias_scale:.2f}\")\n",
        "\n",
        "# Step 2: Quantize and save\n",
        "for i in [0, 2, 4]:\n",
        "    weights, biases = model.layers[i].get_weights()\n",
        "\n",
        "    # Quantize using calibrated scales\n",
        "    weights_q = np.round(weights * layer_scales[i]['weight_scale']).astype(np.int8)\n",
        "    biases_q = np.round(biases * layer_scales[i]['bias_scale']).astype(np.int8)\n",
        "\n",
        "    # Save quantized values\n",
        "    np.savetxt(f'layer_{i}_weights_calibrated.txt', weights_q, fmt='%d')\n",
        "    np.savetxt(f'layer_{i}_biases_calibrated.txt', biases_q, fmt='%d')\n",
        "\n",
        "# Quantize test samples\n",
        "X_test_10_q = np.round(X_test[:10] * input_scale).astype(np.int8)\n",
        "np.savetxt('X_test_10_calibrated.txt', X_test_10_q, fmt='%d')\n",
        "\n",
        "# Save scales for inference\n",
        "import json\n",
        "scales_data = {\n",
        "    'input_scale': input_scale,\n",
        "    'layer_scales': layer_scales\n",
        "}\n",
        "with open('calibrated_scales.json', 'w') as f:\n",
        "    json.dump(scales_data, f)\n",
        "\n",
        "print(\"Calibrated quantization completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMjv6QCwVm18",
        "outputId": "4106a0b5-4d1d-4bcf-de51-bcb9c75639e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibrating quantization scales...\n",
            "Input scale: 35.47\n",
            "Layer 0: weight_scale=426.22, bias_scale=150.05\n",
            "Layer 2: weight_scale=308.87, bias_scale=429.52\n",
            "Layer 4: weight_scale=305.11, bias_scale=230.26\n",
            "Calibrated quantization completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evX9avCmWIAn",
        "outputId": "f8137553-53f9-4bba-cd54-b7c75f071352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 3 2 5 8 5 5 4 7 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Recreate y_test_10.txt\n",
        "np.savetxt('y_test_10.txt', y_test[:10], fmt='%d')\n",
        "print(\"y_test_10.txt recreated\")\n",
        "\n",
        "# Load calibrated scales\n",
        "with open('calibrated_scales.json', 'r') as f:\n",
        "    scales_data = json.load(f)\n",
        "\n",
        "input_scale = scales_data['input_scale']\n",
        "layer_scales = scales_data['layer_scales']\n",
        "\n",
        "# Load calibrated quantized weights\n",
        "w0 = np.loadtxt('layer_0_weights_calibrated.txt', dtype=np.int8)\n",
        "b0 = np.loadtxt('layer_0_biases_calibrated.txt', dtype=np.int8)\n",
        "w1 = np.loadtxt('layer_2_weights_calibrated.txt', dtype=np.int8)\n",
        "b1 = np.loadtxt('layer_2_biases_calibrated.txt', dtype=np.int8)\n",
        "w2 = np.loadtxt('layer_4_weights_calibrated.txt', dtype=np.int8)\n",
        "b2 = np.loadtxt('layer_4_biases_calibrated.txt', dtype=np.int8)\n",
        "\n",
        "# Load calibrated test samples\n",
        "X_test_10_q = np.loadtxt('X_test_10_calibrated.txt', dtype=np.int8)\n",
        "y_test_10 = np.loadtxt('y_test_10.txt', dtype=int)\n",
        "\n",
        "# Forward pass with proper dequantization\n",
        "def forward_calibrated(sample):\n",
        "    # Dequantize input\n",
        "    x = sample.astype(np.float32) / input_scale\n",
        "\n",
        "    # Layer 1\n",
        "    w0_float = w0.astype(np.float32) / layer_scales['0']['weight_scale']\n",
        "    b0_float = b0.astype(np.float32) / layer_scales['0']['bias_scale']\n",
        "    x1 = np.maximum(0, np.dot(x, w0_float) + b0_float)\n",
        "\n",
        "    # Layer 2\n",
        "    w1_float = w1.astype(np.float32) / layer_scales['2']['weight_scale']\n",
        "    b1_float = b1.astype(np.float32) / layer_scales['2']['bias_scale']\n",
        "    x2 = np.maximum(0, np.dot(x1, w1_float) + b1_float)\n",
        "\n",
        "    # Output layer\n",
        "    w2_float = w2.astype(np.float32) / layer_scales['4']['weight_scale']\n",
        "    b2_float = b2.astype(np.float32) / layer_scales['4']['bias_scale']\n",
        "    out = np.dot(x2, w2_float) + b2_float\n",
        "\n",
        "    return out\n",
        "\n",
        "# Test on 10 samples\n",
        "correct = 0\n",
        "for i in range(10):\n",
        "    logits = forward_calibrated(X_test_10_q[i])\n",
        "    pred = np.argmax(logits)\n",
        "    print(f\"Sample {i} true: {y_test_10[i]}, predicted: {pred}, raw output: {logits}\")\n",
        "    if pred == y_test_10[i]:\n",
        "        correct += 1\n",
        "\n",
        "print(f\"\\nCalibrated quantization accuracy: {correct/10:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALrwRKVV1Uc",
        "outputId": "21fbcade-507a-45c0-fc9b-11a791d89324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_test_10.txt recreated\n",
            "Sample 0 true: 5, predicted: 4, raw output: [-1.0879385   0.43255955 -1.2469054  -0.7812417   0.8300883  -0.76228994\n",
            " -0.48957953  0.463717    0.611089    0.3696332 ]\n",
            "Sample 1 true: 3, predicted: 8, raw output: [-5.5844152e-01  2.4712307e+00 -1.8590285e+00  3.2180297e+00\n",
            " -6.5833149e+00  2.9692054e-03 -8.7241364e+00  2.2954402e+00\n",
            "  3.7257717e+00 -8.2604542e+00]\n",
            "Sample 2 true: 2, predicted: 2, raw output: [-4.3451624  1.1088964  5.6740494  1.5615486 -2.9800155 -2.0918577\n",
            " -6.669729   4.7493844  4.359181  -5.9626913]\n",
            "Sample 3 true: 5, predicted: 5, raw output: [-3.3266015  2.6810148 -4.4391527  2.9304082 -3.3108974  3.7099924\n",
            " -7.459942  -0.9082233 -1.6475892 -3.6820636]\n",
            "Sample 4 true: 8, predicted: 8, raw output: [-1.7577827  -0.5284489  -6.412081   -0.49341196  2.1047523  -1.9517553\n",
            " -4.971651    2.9933586  10.970776   -5.459069  ]\n",
            "Sample 5 true: 5, predicted: 5, raw output: [-1.6758196  -0.52908415 -2.9690535   1.3910213  -0.05670658  1.5517726\n",
            " -3.2060254  -0.9565002   0.54477406 -1.8723142 ]\n",
            "Sample 6 true: 5, predicted: 4, raw output: [-1.1713123  -1.6103387  -4.8847547  -1.1358631   2.5269513   0.6735637\n",
            "  0.5904088  -2.813539    0.50682074  0.34534585]\n",
            "Sample 7 true: 4, predicted: 4, raw output: [ -0.24540079  -0.55745375 -10.101377    -4.7753487   10.559432\n",
            "  -1.539578     4.941274    -5.3405795   -4.0469155    5.7848067 ]\n",
            "Sample 8 true: 7, predicted: 8, raw output: [-1.9397712  -0.23457453 -0.5238057  -1.2415488  -0.11397035 -0.18223614\n",
            " -2.533362   -0.04233509  1.2992465  -0.7237638 ]\n",
            "Sample 9 true: 2, predicted: 2, raw output: [ 4.5045943  -2.5371797  12.261931    4.386103   -3.7447736   0.24658197\n",
            " -2.7555578  -5.590241   -3.859192   -5.913676  ]\n",
            "\n",
            "Calibrated quantization accuracy: 0.60\n",
            "Target (TensorFlow Lite): 0.70\n",
            "Improvement over naive quantization: 0.60 vs 0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Load your calibrated scales\n",
        "with open('calibrated_scales.json', 'r') as f:\n",
        "    scales_data = json.load(f)\n",
        "\n",
        "print(\"Analyzing data ranges for Q8.8 compatibility...\")\n",
        "\n",
        "# Check input range\n",
        "X_test_q = np.loadtxt('X_test_10_calibrated.txt', dtype=np.int8)\n",
        "X_test_float = X_test_q.astype(np.float32) / scales_data['input_scale']\n",
        "print(f\"Input range: [{X_test_float.min():.4f}, {X_test_float.max():.4f}]\")\n",
        "\n",
        "# Check each layer's weight and bias ranges\n",
        "for i in [0, 2, 4]:\n",
        "    weights_q = np.loadtxt(f'layer_{i}_weights_calibrated.txt', dtype=np.int8)\n",
        "    biases_q = np.loadtxt(f'layer_{i}_biases_calibrated.txt', dtype=np.int8)\n",
        "\n",
        "    weights_float = weights_q.astype(np.float32) / scales_data['layer_scales'][str(i)]['weight_scale']\n",
        "    biases_float = biases_q.astype(np.float32) / scales_data['layer_scales'][str(i)]['bias_scale']\n",
        "\n",
        "    print(f\"Layer {i} weights: [{weights_float.min():.4f}, {weights_float.max():.4f}]\")\n",
        "    print(f\"Layer {i} biases: [{biases_float.min():.4f}, {biases_float.max():.4f}]\")\n",
        "\n",
        "print(f\"\\nQ8.8 format range: [-128.0, +127.996]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J6lHomPV_TJ",
        "outputId": "1843c07c-6447-4487-d2bd-32d968e9af08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing data ranges for Q8.8 compatibility...\n",
            "Input range: [-3.6088, 3.5524]\n",
            "Layer 0 weights: [-0.3003, 0.2980]\n",
            "Layer 0 biases: [-0.8464, -0.1866]\n",
            "Layer 2 weights: [-0.4144, 0.4112]\n",
            "Layer 2 biases: [-0.2957, 0.2654]\n",
            "Layer 4 weights: [-0.4195, 0.3999]\n",
            "Layer 4 biases: [-0.5516, 0.5168]\n",
            "\n",
            "Q8.8 format range: [-128.0, +127.996]\n",
            "If any values are outside this range, we need a different format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Load your calibrated scales\n",
        "with open('calibrated_scales.json', 'r') as f:\n",
        "    scales_data = json.load(f)\n",
        "\n",
        "def int8_to_q88(value_int8, scale):\n",
        "    \"\"\"Convert int8 quantized value to Q8.8 fixed-point\"\"\"\n",
        "    # First convert back to float\n",
        "    value_float = value_int8.astype(np.float32) / scale\n",
        "    # Then convert to Q8.8 (multiply by 2^8 = 256)\n",
        "    value_q88 = np.round(value_float * 256).astype(np.int16)\n",
        "    return value_q88\n",
        "\n",
        "def q88_to_hex(value_q88):\n",
        "    \"\"\"Convert Q8.8 value to hex string for Verilog\"\"\"\n",
        "    # Handle negative numbers (two's complement)\n",
        "    if value_q88 < 0:\n",
        "        value_q88 = value_q88 + 65536  # Add 2^16 for two's complement\n",
        "    return f\"{value_q88:04X}\"\n",
        "\n",
        "print(\"Converting to Q8.8 fixed-point format...\")\n",
        "\n",
        "# Convert weights and biases for each layer\n",
        "for i in [0, 2, 4]:\n",
        "    # Load quantized values\n",
        "    weights_q = np.loadtxt(f'layer_{i}_weights_calibrated.txt', dtype=np.int8)\n",
        "    biases_q = np.loadtxt(f'layer_{i}_biases_calibrated.txt', dtype=np.int8)\n",
        "\n",
        "    # Convert to Q8.8\n",
        "    weights_q88 = int8_to_q88(weights_q, scales_data['layer_scales'][str(i)]['weight_scale'])\n",
        "    biases_q88 = int8_to_q88(biases_q, scales_data['layer_scales'][str(i)]['bias_scale'])\n",
        "\n",
        "    # Save as decimal for testing\n",
        "    np.savetxt(f'layer_{i}_weights_q88.txt', weights_q88, fmt='%d')\n",
        "    np.savetxt(f'layer_{i}_biases_q88.txt', biases_q88, fmt='%d')\n",
        "\n",
        "    print(f\"Layer {i}: converted to Q8.8 format\")\n",
        "    print(f\"  Weights range: [{weights_q88.min()}, {weights_q88.max()}]\")\n",
        "    print(f\"  Biases range: [{biases_q88.min()}, {biases_q88.max()}]\")\n",
        "\n",
        "# Convert test inputs\n",
        "X_test_q = np.loadtxt('X_test_10_calibrated.txt', dtype=np.int8)\n",
        "X_test_q88 = int8_to_q88(X_test_q, scales_data['input_scale'])\n",
        "np.savetxt('X_test_10_q88.txt', X_test_q88, fmt='%d')\n",
        "\n",
        "print(f\"Inputs range: [{X_test_q88.min()}, {X_test_q88.max()}]\")\n",
        "print(\"\\nQ8.8 conversion completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwSe3es3bKYd",
        "outputId": "5cc7b3fa-fa47-45ec-eac8-b4e7626496f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting to Q8.8 fixed-point format...\n",
            "Layer 0: converted to Q8.8 format\n",
            "  Weights range: [-77, 76]\n",
            "  Biases range: [-217, -48]\n",
            "Layer 2: converted to Q8.8 format\n",
            "  Weights range: [-106, 105]\n",
            "  Biases range: [-76, 68]\n",
            "Layer 4: converted to Q8.8 format\n",
            "  Weights range: [-107, 102]\n",
            "  Biases range: [-141, 132]\n",
            "Inputs range: [-924, 909]\n",
            "\n",
            "Q8.8 conversion completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load Q8.8 fixed-point weights and biases\n",
        "w0_q88 = np.loadtxt('layer_0_weights_q88.txt', dtype=np.int16)\n",
        "b0_q88 = np.loadtxt('layer_0_biases_q88.txt', dtype=np.int16)\n",
        "w1_q88 = np.loadtxt('layer_2_weights_q88.txt', dtype=np.int16)\n",
        "b1_q88 = np.loadtxt('layer_2_biases_q88.txt', dtype=np.int16)\n",
        "w2_q88 = np.loadtxt('layer_4_weights_q88.txt', dtype=np.int16)\n",
        "b2_q88 = np.loadtxt('layer_4_biases_q88.txt', dtype=np.int16)\n",
        "\n",
        "# Load Q8.8 test inputs\n",
        "X_test_q88 = np.loadtxt('X_test_10_q88.txt', dtype=np.int16)\n",
        "y_test_10 = np.loadtxt('y_test_10.txt', dtype=int)\n",
        "\n",
        "def q88_to_float(q88_value):\n",
        "    \"\"\"Convert Q8.8 fixed-point to float for testing\"\"\"\n",
        "    return q88_value.astype(np.float32) / 256.0\n",
        "\n",
        "def simulate_q88_math(sample_q88):\n",
        "    \"\"\"Simulate Q8.8 fixed-point math (what Verilog will do)\"\"\"\n",
        "\n",
        "    # Convert Q8.8 to float for this simulation\n",
        "    x = q88_to_float(sample_q88)\n",
        "    w0 = q88_to_float(w0_q88)\n",
        "    b0 = q88_to_float(b0_q88)\n",
        "    w1 = q88_to_float(w1_q88)\n",
        "    b1 = q88_to_float(b1_q88)\n",
        "    w2 = q88_to_float(w2_q88)\n",
        "    b2 = q88_to_float(b2_q88)\n",
        "\n",
        "    # Layer 1: input -> hidden1\n",
        "    x1 = np.maximum(0, np.dot(x, w0) + b0)  # ReLU\n",
        "\n",
        "    # Layer 2: hidden1 -> hidden2\n",
        "    x2 = np.maximum(0, np.dot(x1, w1) + b1)  # ReLU\n",
        "\n",
        "    # Output layer: hidden2 -> output\n",
        "    out = np.dot(x2, w2) + b2\n",
        "\n",
        "    return out\n",
        "\n",
        "# Test Q8.8 accuracy\n",
        "correct = 0\n",
        "print(\"Testing Q8.8 fixed-point accuracy:\")\n",
        "for i in range(10):\n",
        "    logits = simulate_q88_math(X_test_q88[i])\n",
        "    pred = np.argmax(logits)\n",
        "    print(f\"Sample {i} true: {y_test_10[i]}, predicted: {pred}\")\n",
        "    if pred == y_test_10[i]:\n",
        "        correct += 1\n",
        "\n",
        "q88_accuracy = correct / 10\n",
        "print(f\"\\nAccuracy comparison:\")\n",
        "print(f\"Original float model: 0.85\")\n",
        "print(f\"Calibrated quantization: 0.60\")\n",
        "print(f\"Q8.8 fixed-point: {q88_accuracy:.2f}\")\n",
        "print(f\"Accuracy loss from Q8.8 conversion: {0.60 - q88_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRDvM4k5bZAi",
        "outputId": "6478d0c1-643c-46dd-a9fe-450a0380ccad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Q8.8 fixed-point accuracy:\n",
            "Sample 0 true: 5, predicted: 4\n",
            "Sample 1 true: 3, predicted: 8\n",
            "Sample 2 true: 2, predicted: 2\n",
            "Sample 3 true: 5, predicted: 5\n",
            "Sample 4 true: 8, predicted: 8\n",
            "Sample 5 true: 5, predicted: 5\n",
            "Sample 6 true: 5, predicted: 4\n",
            "Sample 7 true: 4, predicted: 4\n",
            "Sample 8 true: 7, predicted: 8\n",
            "Sample 9 true: 2, predicted: 2\n",
            "\n",
            "Accuracy comparison:\n",
            "Original float model: 0.85\n",
            "Calibrated quantization: 0.60\n",
            "Q8.8 fixed-point: 0.60\n",
            "Accuracy loss from Q8.8 conversion: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_verilog_rom_q88(module_name, data_file, output_file, is_2d=True):\n",
        "    \"\"\"Generate Verilog ROM module for Q8.8 fixed-point data\"\"\"\n",
        "\n",
        "    # Load data\n",
        "    data = np.loadtxt(data_file, dtype=np.int16)\n",
        "    if data.ndim == 1:\n",
        "        data = data.reshape(-1, 1)\n",
        "\n",
        "    num_rows, num_cols = data.shape\n",
        "    addr_bits = max(1, (num_rows - 1).bit_length())\n",
        "    index_bits = max(1, (num_cols - 1).bit_length()) if num_cols > 1 else 1\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(f\"// Q8.8 Fixed-Point ROM: {module_name}\\n\")\n",
        "        f.write(f\"module {module_name} (\\n\")\n",
        "\n",
        "        if is_2d and num_cols > 1:\n",
        "            f.write(f\"    input [{addr_bits-1}:0] addr,\\n\")\n",
        "            f.write(f\"    input [{index_bits-1}:0] index,\\n\")\n",
        "            f.write( \"    output reg signed [15:0] data_out\\n\")\n",
        "        else:\n",
        "            f.write(f\"    input [{addr_bits-1}:0] addr,\\n\")\n",
        "            f.write( \"    output reg signed [15:0] data_out\\n\")\n",
        "\n",
        "        f.write(\");\\n\\n\")\n",
        "\n",
        "        if is_2d and num_cols > 1:\n",
        "            f.write(f\"    reg signed [15:0] rom [0:{num_rows-1}][0:{num_cols-1}];\\n\\n\")\n",
        "        else:\n",
        "            f.write(f\"    reg signed [15:0] rom [0:{num_rows-1}];\\n\\n\")\n",
        "\n",
        "        f.write(\"    initial begin\\n\")\n",
        "\n",
        "        if is_2d and num_cols > 1:\n",
        "            for r in range(num_rows):\n",
        "                for c in range(num_cols):\n",
        "                    # Convert to 16-bit two's complement hex\n",
        "                    val = int(data[r][c])\n",
        "                    if val < 0:\n",
        "                        val = val + 65536  # Two's complement\n",
        "                    f.write(f\"        rom[{r}][{c}] = 16'h{val:04X};\\n\")\n",
        "        else:\n",
        "            for r in range(num_rows):\n",
        "                val = int(data[r][0] if num_cols > 1 else data[r])\n",
        "                if val < 0:\n",
        "                    val = val + 65536\n",
        "                f.write(f\"        rom[{r}] = 16'h{val:04X};\\n\")\n",
        "\n",
        "        f.write(\"    end\\n\\n\")\n",
        "\n",
        "        if is_2d and num_cols > 1:\n",
        "            f.write(\"    always @(*) begin\\n\")\n",
        "            f.write(\"        data_out = rom[addr][index];\\n\")\n",
        "            f.write(\"    end\\n\")\n",
        "        else:\n",
        "            f.write(\"    always @(*) begin\\n\")\n",
        "            f.write(\"        data_out = rom[addr];\\n\")\n",
        "            f.write(\"    end\\n\")\n",
        "\n",
        "        f.write(\"endmodule\\n\")\n",
        "\n",
        "    print(f\"✅ Generated: {output_file} ({num_rows} × {num_cols})\")\n",
        "\n",
        "# Generate ROM modules for all layers\n",
        "print(\"Generating Verilog ROM modules...\")\n",
        "\n",
        "# Layer 0 (1274 × 256)\n",
        "generate_verilog_rom_q88(\"rom_layer0_weights\", \"layer_0_weights_q88.txt\", \"rom_layer0_weights.v\", is_2d=True)\n",
        "generate_verilog_rom_q88(\"rom_layer0_biases\", \"layer_0_biases_q88.txt\", \"rom_layer0_biases.v\", is_2d=False)\n",
        "\n",
        "# Layer 2 (256 × 128)\n",
        "generate_verilog_rom_q88(\"rom_layer2_weights\", \"layer_2_weights_q88.txt\", \"rom_layer2_weights.v\", is_2d=True)\n",
        "generate_verilog_rom_q88(\"rom_layer2_biases\", \"layer_2_biases_q88.txt\", \"rom_layer2_biases.v\", is_2d=False)\n",
        "\n",
        "# Layer 4 (128 × 10)\n",
        "generate_verilog_rom_q88(\"rom_layer4_weights\", \"layer_4_weights_q88.txt\", \"rom_layer4_weights.v\", is_2d=True)\n",
        "generate_verilog_rom_q88(\"rom_layer4_biases\", \"layer_4_biases_q88.txt\", \"rom_layer4_biases.v\", is_2d=False)\n",
        "\n",
        "# Test inputs (10 × 1274)\n",
        "generate_verilog_rom_q88(\"rom_test_inputs\", \"X_test_10_q88.txt\", \"rom_test_inputs.v\", is_2d=True)\n",
        "\n",
        "print(\"\\n🎉 All Verilog ROM modules generated!\")\n",
        "print(\"Files created:\")\n",
        "print(\"- rom_layer0_weights.v\")\n",
        "print(\"- rom_layer0_biases.v\")\n",
        "print(\"- rom_layer2_weights.v\")\n",
        "print(\"- rom_layer2_biases.v\")\n",
        "print(\"- rom_layer4_weights.v\")\n",
        "print(\"- rom_layer4_biases.v\")\n",
        "print(\"- rom_test_inputs.v\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NNRxOBdcLQZ",
        "outputId": "889e9ce4-14db-471f-b4f9-8673c0fe1063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Verilog ROM modules...\n",
            "✅ Generated: rom_layer0_weights.v (1274 × 256)\n",
            "✅ Generated: rom_layer0_biases.v (256 × 1)\n",
            "✅ Generated: rom_layer2_weights.v (256 × 128)\n",
            "✅ Generated: rom_layer2_biases.v (128 × 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-71-3361478629.py:46: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  val = int(data[r][0] if num_cols > 1 else data[r])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated: rom_layer4_weights.v (128 × 10)\n",
            "✅ Generated: rom_layer4_biases.v (10 × 1)\n",
            "✅ Generated: rom_test_inputs.v (10 × 1274)\n",
            "\n",
            "🎉 All Verilog ROM modules generated!\n",
            "Files created:\n",
            "- rom_layer0_weights.v\n",
            "- rom_layer0_biases.v\n",
            "- rom_layer2_weights.v\n",
            "- rom_layer2_biases.v\n",
            "- rom_layer4_weights.v\n",
            "- rom_layer4_biases.v\n",
            "- rom_test_inputs.v\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sRpggtrdcdRh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}